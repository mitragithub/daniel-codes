{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import emlddmm\n",
    "import json\n",
    "import nrrd\n",
    "import os\n",
    "import imp\n",
    "imp.reload(emlddmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note slices are 14.72\n",
    "# 14.72*4 = 58.88 # corresponds to atlas downsampling 1\n",
    "# 14.72*7 = 103.04 # atlas downsampling 2\n",
    "# 14.72*14 = 206.08 # downsampling 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to do\n",
    "# common interface for load images\n",
    "# make sure all fields in input datasets are read correctly\n",
    "# command line interface\n",
    "# preprocessing (here we are doing downsampling)\n",
    "# apply transforms to other data\n",
    "# profiling (optional profiling?)\n",
    "# check metrics for gradient descent and update\n",
    "\n",
    "# release to do\n",
    "# readme page\n",
    "# license\n",
    "# documentation: \n",
    "# * explain mandatory inputs\n",
    "# * explain config file\n",
    "# * explain dataset format\n",
    "# * explain output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo\n",
    "# finish command line interface\n",
    "# finish vtk io (done)\n",
    "# add slice by slice tform\n",
    "# check outputs\n",
    "# double check whole brain works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get whole brain working\n",
    "# add tool for applying transforms\n",
    "# visualization in reconstructed space during reg\n",
    "# fix up vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_name = 'C:\\\\Users\\\\BGAdmin\\\\data\\\\Allen_Atlas_vtk\\\\ara_nissl_50.vtk'\n",
    "label_name = 'C:\\\\Users\\\\BGAdmin\\\\data\\\\Allen_Atlas_vtk\\\\annotation_50.vtk'\n",
    "target_name = 'C:\\\\Users\\\\BGAdmin\\\\data\\\\MD816\\\\MD816_STIF'\n",
    "config_file = 'config787.json'\n",
    "output_dir = 'test_outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file) as f:\n",
    "    config = json.load(f)\n",
    "# I'm getting this for initial downsampling for preprocessing\n",
    "downJs = config['downJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atlas test\n",
    "imp.reload(emlddmm)\n",
    "xI,I,title,names = emlddmm.read_vtk_data(atlas_name)\n",
    "I = I.astype(float)\n",
    "fig = emlddmm.draw(I,xI)\n",
    "fig[0].suptitle('Atlas image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xS,S,title,names = emlddmm.read_vtk_data(label_name)\n",
    "fig = emlddmm.draw(S%7,xS)\n",
    "fig[0].suptitle('Atlas segs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xJ,J,W0 = emlddmm.load_slices(target_name)\n",
    "nJ = np.array(J.shape)\n",
    "dJ = np.array([xJ[0][1]-xJ[0][0], xJ[1][1]-xJ[1][0],xJ[2][1]-xJ[2][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial downsampling so there isn't so much on the gpu\n",
    "mindownJ = np.min(np.array(downJs),0)\n",
    "xJ,J = emlddmm.downsample_image_domain(xJ,J,mindownJ)\n",
    "W0 = emlddmm.downsample(W0,mindownJ)\n",
    "downJs = [ (np.array(d)/mindownJ).astype(int) for d in downJs]\n",
    "dJ = np.array((xJ[0][1]-xJ[0][0],xJ[1][1]-xJ[1][0],xJ[2][1]-xJ[2][0]))\n",
    "nJ = np.array(J.shape,dtype=int)\n",
    "# update our config variable\n",
    "config['downJ'] = downJs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emlddmm.draw(J,xJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(emlddmm)\n",
    "# visualize initial affine\n",
    "A = np.array(config['A']).astype(float)\n",
    "# this affine matrix should be 4x4, but it may be 1x4x4\n",
    "if A.ndim > 2:\n",
    "    A = A[0]\n",
    "Ai = np.linalg.inv(A)\n",
    "XJ = np.stack(np.meshgrid(*xJ,indexing='ij'),-1)\n",
    "Xs = (Ai[:3,:3]@XJ[...,None])[...,0] + Ai[:3,-1]\n",
    "out = emlddmm.interp(xI,I,Xs.transpose((3,0,1,2)))\n",
    "fig = emlddmm.draw(out,xJ)\n",
    "fig[0].suptitle('Initial transformed atlas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to be able to compose transforms and get a final sample space\n",
    "# the inputs need to be either position fields\n",
    "# or matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# device = 'cpu'\n",
    "device = 'cuda:0'\n",
    "\n",
    "output = emlddmm.emlddmm_multiscale(I=I,xI=[xI],J=J,xJ=[xJ],W0=W0,device=device,**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(emlddmm)\n",
    "emlddmm.write_transform_outputs(output_dir,output[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp.reload(emlddmm)\n",
    "emlddmm.write_qc_outputs(output_dir,output[-1],xI,I,xJ,J,xS=xI,S=S.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emlddmm.draw(I)\n",
    "emlddmm.draw(S%7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low resolution brain volume in registered space for each modality\n",
    "# low resolution deformed atalas and annotation in registered space.\n",
    "# and low resolution data in atlas space\n",
    "# (daniel double check)\n",
    "#\n",
    "# things you need for the web interface\n",
    "# 1. annotations as a geojson file in registered space # include orientation and pixel resolution\n",
    "# 2. sagittal navigation (text file with mean x mean y mean z)\n",
    "# 3. A matrix for transforming high resolution images (for portal and for other stuff).\n",
    "# 4. Grid lines as geojson file\n",
    "#\n",
    "# Share with Xu on Monday.\n",
    "#\n",
    "# TODO: manual correction\n",
    "# editing rigid transformation matrices\n",
    "# we should be able to use the same tool, but we have to test it.\n",
    "# \n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BREGMA shift\n",
    "# proposal number 1:\n",
    "# Everything that is being shown on the web needs to be updated\n",
    "# 1. annotions as a geojson file [all the data in the file will have to be shifted]\n",
    "# 2. sagittal navigation (all the data in the file will have to be shifted)\n",
    "# 3. A matrix for transforming high resolution images (the translation part will have to be shifted)\n",
    "# 4. Grid lines (all the data will have to be shifted)\n",
    "# \n",
    "# proposal number 2 alternative suggestion:\n",
    "# 1. just display the bregma on the viewer and don't modify any current results.\n",
    "# \n",
    "# proposal number 3:\n",
    "# 1. keep annotations the same\n",
    "# 2. shift the sagittal navigation \n",
    "# 3. keep transformation matrices the same\n",
    "# 4. Grid lines, shift the labels not the data\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Xu\n",
    "\n",
    "Hi Daniel:\n",
    "\n",
    "Here is what we need:\n",
    "\n",
    "A low resolution(10 or 50um) brain volume in registered space for each modality: these volumes should have the same dimensions, if one modality has fewer sections compared to another, we can use blank sections to fill the gap.\n",
    " \n",
    "Low resolution deformed atlas and annotation in registered space: also the same dimension as the registered brain volume.\n",
    "\n",
    "I can only come up with these two right now, Bingxing do you have anything to add?\n",
    "\n",
    "Sincerely\n",
    "Xu Li"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53a584f8262ceeeafe7af65b66bf0446ad5d9e62941ae7c953bbefa83b16196b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
